{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras import layers\nfrom keras.layers import GlobalAveragePooling2D,Activation,Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D, Concatenate\nfrom keras import applications\nimport numpy as np\nimport tensorflow.keras as keras","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:47:12.213295Z","iopub.execute_input":"2022-04-27T07:47:12.213543Z","iopub.status.idle":"2022-04-27T07:47:12.219204Z","shell.execute_reply.started":"2022-04-27T07:47:12.213516Z","shell.execute_reply":"2022-04-27T07:47:12.218530Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ROWS=224\nCOLS=224\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.densenet import preprocess_input\ntrain_idg = ImageDataGenerator(vertical_flip=True,\n                               horizontal_flip=True,\n                               height_shift_range=0.1,\n                               width_shift_range=0.1,\n                               rotation_range=27,\n                               preprocessing_function=preprocess_input)\ntrain_gen = train_idg.flow_from_directory(\n    '../input/datatask1/task1/train',\n    target_size=(ROWS, COLS),\n    batch_size = 64\n)\nval_datagen = ImageDataGenerator(rescale=1/255)\nval_gen = val_datagen.flow_from_directory(\n    '../input/datatask1/task1/val',\n    target_size=(ROWS, COLS),\n    batch_size = 16\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:46:34.707851Z","iopub.execute_input":"2022-04-27T07:46:34.708110Z","iopub.status.idle":"2022-04-27T07:46:37.970609Z","shell.execute_reply.started":"2022-04-27T07:46:34.708068Z","shell.execute_reply":"2022-04-27T07:46:37.969843Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"input_shape = (ROWS, COLS, 3)\nnclass = len(train_gen.class_indices)\n\nbase_model = tf.keras.applications.DenseNet169(weights='imagenet', \n                                include_top=False, \n                                input_shape=(ROWS, COLS,3))\n\nbase_model.trainable = False\n\nadd_model = Sequential()\nadd_model.add(base_model)\n'''add_model.add(tf.keras.layers.Conv2D(64,kernel_size=(3,3)))\nadd_model.add(BatchNormalization())\nadd_model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\nadd_model.add(tf.keras.layers.Conv2D(32,kernel_size=(3,3)))\nadd_model.add(BatchNormalization())\nadd_model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n'''\nadd_model.add(GlobalAveragePooling2D())\nadd_model.add(Dropout(0.3))\nadd_model.add(Dense(nclass, \n                    activation='softmax'))\n\nmodel = add_model\nmetrics = METRICS = [\n    tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n    tf.keras.metrics.Precision(name=\"precison\"),\n    tf.keras.metrics.Recall(name=\"recall\")\n]\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=metrics)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:47:16.877004Z","iopub.execute_input":"2022-04-27T07:47:16.877269Z","iopub.status.idle":"2022-04-27T07:47:21.171821Z","shell.execute_reply.started":"2022-04-27T07:47:16.877242Z","shell.execute_reply":"2022-04-27T07:47:21.171063Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nfile_path=\"weights.best.hdf5\"\n\nes = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\nmc = keras.callbacks.ModelCheckpoint('best_model_alt-loss-resnet.h5', monitor='loss', mode='min', save_best_only=True)\nms = keras.callbacks.ModelCheckpoint('best_model_alt-valloss-resnet.h5', monitor='val_loss', mode='min', save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\ncallbacks_list = [es, mc,ms,reduce_lr] #early\nwith tf.device('/gpu:0'):\n    history = model.fit_generator(train_gen,\n                              validation_data=val_gen, \n                              epochs=50, \n                              shuffle=True, \n                              verbose=True,\n                              callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:47:27.492049Z","iopub.execute_input":"2022-04-27T07:47:27.492323Z","iopub.status.idle":"2022-04-27T10:24:12.929882Z","shell.execute_reply.started":"2022-04-27T07:47:27.492291Z","shell.execute_reply":"2022-04-27T10:24:12.929152Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"savemodel = tf.keras.models.load_model('best_model_alt-valloss-resnet.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:35:26.288665Z","iopub.execute_input":"2022-04-27T10:35:26.288960Z","iopub.status.idle":"2022-04-27T10:36:27.579098Z","shell.execute_reply.started":"2022-04-27T10:35:26.288931Z","shell.execute_reply":"2022-04-27T10:36:27.578363Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\npredicted=[]\nreal=[]\nfor dir in os.listdir(\"../input/datatask1/task1/test\"):\n    if dir=='informative':\n        r=0\n    else:\n        r=1\n    for path in os.listdir(f'../input/datatask1/task1/test/{dir}'):\n        p=f'../input/datatask1/task1/test/{dir}/{path}'\n        img = tf.keras.utils.load_img(\n    p, target_size=(224, 224)\n)\n        img_array = tf.keras.utils.img_to_array(img)\n        img_array = tf.expand_dims(img_array, 0) # Create a batch\n        img_array=preprocess_input(img_array)\n\n        predictions = savemodel.predict(img_array)\n        real.append(r)\n        predicted.append(np.argmax(predictions))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:36:27.580988Z","iopub.execute_input":"2022-04-27T10:36:27.581227Z","iopub.status.idle":"2022-04-27T10:38:52.035693Z","shell.execute_reply.started":"2022-04-27T10:36:27.581195Z","shell.execute_reply":"2022-04-27T10:38:52.034955Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(real,predicted))\nprint(metrics.confusion_matrix(real,predicted))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:38:52.040115Z","iopub.execute_input":"2022-04-27T10:38:52.041991Z","iopub.status.idle":"2022-04-27T10:38:52.644969Z","shell.execute_reply.started":"2022-04-27T10:38:52.041949Z","shell.execute_reply":"2022-04-27T10:38:52.643425Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:39:06.010426Z","iopub.execute_input":"2022-04-27T10:39:06.011107Z","iopub.status.idle":"2022-04-27T10:39:06.405085Z","shell.execute_reply.started":"2022-04-27T10:39:06.011070Z","shell.execute_reply":"2022-04-27T10:39:06.404417Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}